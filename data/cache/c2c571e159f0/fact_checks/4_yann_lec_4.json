{
  "doc_id": "4_yann_lec",
  "doc_title": "4. Yann LeCun on Open Source AI and AGI",
  "claim_idx": 4,
  "claim": "Autoregressive token-by-token generation causes hallucinations and error accumulation (a probabilistic drift that grows with sequence length and with out-of-distribution prompts), because LLMs are effectively giant conditional next-token predictors trained on a tiny fraction of the possible prompts; achieving robust reasoning and long-form correctness requires different architectures\u2014energy/objective-based models that optimize in continuous latent representation space with gradient-based inference and explicit critics/reward models.",
  "veracity": 65,
  "explanation": "Partly true but overstated. Evidence shows autoregressive next-token training leads to exposure bias/compounding errors that can increase hallucinations for long outputs and out-of-distribution prompts. ([arxiv.org](https://arxiv.org/abs/1506.03099?utm_source=chatgpt.com), [pmc.ncbi.nlm.nih.gov](https://pmc.ncbi.nlm.nih.gov/articles/PMC11815294/?utm_source=chatgpt.com)) LLMs are in practice trained as conditional next-token predictors (e.g., GPT-3). ([arxiv.org](https://arxiv.org/abs/2005.14165?utm_source=chatgpt.com)) There is active, peer\u2011reviewed work on non\u2011autoregressive / continuous latent / energy/diffusion approaches (e.g., Diffusion\u2011LM and recent EBM surveys) that can enable gradient-based inference and better controllability in some settings. ([arxiv.org](https://arxiv.org/abs/2205.14217?utm_source=chatgpt.com)) Meanwhile, explicit critics/reward tuning such as RLHF (InstructGPT) and retrieval-augmentation are proven practical mitigations that improve truthfulness without abandoning autoregressive architectures. ([arxiv.org](https://arxiv.org/abs/2203.02155?utm_source=chatgpt.com)) Therefore the descriptive parts of the claim are accurate, but the stronger prescriptive claim that robust long-form reasoning \u201crequires\u201d a wholesale move to energy/objective-based latent\u2011gradient architectures is currently speculative\u2014promising research exists but no definitive proof that such architectures are the only or necessary solution.",
  "sources": []
}