{
  "doc_id": "4_yann_lec",
  "doc_title": "4. Yann LeCun on Open Source AI and AGI",
  "claim_idx": 1,
  "claim": "Autoregressive large language models (LLMs) trained to predict next tokens are missing essential components of intelligence\u2014robust understanding of the physical world, persistent memory, genuine reasoning and planning\u2014and therefore, while useful for many applications, they are not by themselves the path to human-level (AMI/AGI) intelligence.",
  "veracity": 90,
  "explanation": "Largely accurate. Empirical and expert evidence shows autoregressive next-token LLMs are extremely good at statistical pattern prediction but have well-documented limits: they hallucinate, do not learn persistently from interaction, and exhibit brittle or non-systematic reasoning and planning (OpenAI notes these limits for GPT\u20114). ([arxiv.org](https://arxiv.org/html/2303.08774v4?utm_source=chatgpt.com)) Leading critics and researchers argue these deficiencies reflect missing components\u2014grounded/world models, persistent memory, and explicit planning/reasoning mechanisms\u2014which means LLMs \u201cby themselves\u201d are unlikely to constitute human-level AGI without additional architectures or paradigms. ([dl.acm.org](https://dl.acm.org/doi/abs/10.1145/3442188.3445922?utm_source=chatgpt.com), [arxiv.org](https://arxiv.org/abs/2002.06177?utm_source=chatgpt.com), [techcrunch.com](https://techcrunch.com/2024/10/16/metas-ai-chief-says-world-models-are-key-to-human-level-ai-but-it-might-be-10-years-out/?utm_source=chatgpt.com)) At the same time some researchers report broad, \u201cspark\u201d-like capabilities in very large models but explicitly emphasize the same missing elements and the possibility that progress will require going beyond pure next-token prediction or augmenting LLMs with other systems\u2014so the claim is well-supported but not absolutely certain. ([arxiv.org](https://arxiv.org/abs/2303.12712?utm_source=chatgpt.com))",
  "sources": []
}