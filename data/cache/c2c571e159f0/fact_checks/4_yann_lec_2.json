{
  "doc_id": "4_yann_lec",
  "doc_title": "4. Yann LeCun on Open Source AI and AGI",
  "claim_idx": 2,
  "claim": "Human-like intelligence requires grounding in high-bandwidth sensory experience (vision, touch, audio) because much of the knowledge humans acquire in early development is nonlinguistic and far more redundant than text; language alone (the ~10^13 token corpora) lacks the bandwidth/redundancy to build the rich world models needed for physical reasoning and motor skills.",
  "veracity": 80,
  "explanation": "Largely correct but not proven as an absolute necessity. Developmental research shows infants acquire a great deal of early, non\u2011linguistic, multisensory knowledge and attend preferentially to intersensory (redundant) cues, which supports the claim that much early human learning is nonlinguistic and multimodal. ([journals.sagepub.com](https://journals.sagepub.com/stoken/rbtfl/nOS4kLGgGFE6w/full?utm_source=chatgpt.com)) Theoretical work (the \u2018symbol\u2011grounding\u2019 problem) argues that purely symbolic/textual systems cannot by themselves acquire intrinsic semantic grounding without linking symbols to sensorimotor/perceptual experience. ([southampton.ac.uk](https://www.southampton.ac.uk/~harnad/Papers/Harnad/harnad90.sgproblem.html?utm_source=chatgpt.com)) Neuroscience estimates indicate visual and other sensory channels carry orders of magnitude more raw/bandwidth information than spoken or written language, consistent with the bandwidth/redundancy part of the claim. ([arxiv.org](https://arxiv.org/html/2408.10234v2?utm_source=chatgpt.com)) Empirically, recent ML/robotics work finds embodied or multimodal models (e.g., PaLM\u2011E / SayCan style approaches) materially outperform or enable real\u2011world manipulation and motor tasks that text\u2011only LLMs struggle to solve, supporting the practical need for sensory grounding for physical reasoning and motor skills. ([arxiv.org](https://arxiv.org/abs/2303.03378?utm_source=chatgpt.com)) At the same time, text\u2011only corpora have grown into the trillions of tokens (so the \u201c~10^13 token\u201d scale is now plausible for some datasets), and large text\u2011only LLMs show surprising abstract reasoning abilities\u2014so it remains an open empirical question whether text alone could (in principle) yield full human\u2011like, embodied competence. ([arxiv.org](https://arxiv.org/abs/2311.16867?utm_source=chatgpt.com)) Because the balance of theory and experiments strongly favors the importance (and likely necessity) of high\u2011bandwidth sensory grounding for robust physical/motor competence but does not yet conclusively rule out alternative paths, I rate the claim 80/100.",
  "sources": []
}