{
  "doc_id": "doc_2",
  "claim_idx": 4,
  "claim": "Empirical AI economics suggest: (a) model capability scales roughly with the logarithm of compute/data used; (b) the cost to use a given capability falls about 10\u00d7 every 12 months (e.g., ~150\u00d7 token price drop from GPT-4 in early 2023 to GPT-4o in mid-2024); and (c) the socioeconomic value of linear capability gains is super-exponential, supporting continued exponential investment.",
  "veracity": 30,
  "explanation": "Part (a) is imprecise: empirical scaling laws show model performance (e.g., cross\u2011entropy loss) follows power\u2011law scaling with compute/data, not a simple logarithmic relationship; improvements are roughly linear on log\u2013log plots, not linear in log(compute). ([arxiv.org](https://arxiv.org/abs/2001.08361?utm_source=chatgpt.com)) Part (b) is largely incorrect: OpenAI\u2019s GPT\u20114 8k API in early 2023 was $0.03/$0.06 per 1K input/output tokens, while GPT\u20114o in mid\u20112024 is $0.005/$0.02\u2014about 6\u00d7 cheaper on input and 3\u00d7 on output, not ~150\u00d7, and no clear evidence supports a 10\u00d7 per year cost decline for the same capability. ([help.openai.com](https://help.openai.com/en/articles/7127956-how-much-does-gpt-4-cost%3F.ejs?utm_source=chatgpt.com), [openai.com](https://openai.com/api/pricing/)) Part (c) is speculative and not supported by current evidence: macroeconomic analysis projects modest TFP gains from AI (\u22640.53% over 10 years), while micro studies show notable but bounded productivity improvements (e.g., ~14% for customer support), which do not imply super\u2011exponential socioeconomic value from linear capability gains. ([nber.org](https://www.nber.org/papers/w32487?utm_source=chatgpt.com)) Overall, the claim overstates both the scaling form, the pace of cost declines, and the aggregate economic payoff.",
  "sources": []
}